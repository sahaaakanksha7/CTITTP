{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895107db-10c7-4ea4-a24a-e2939a7193ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from statistics import mode\n",
    "from collections import Counter\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db28ecd4-5a27-473f-898e-4f73e9cfd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    # Get the absolute path of the project root (one directory up)\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "    # Normalize the project_root to ensure it's correctly formatted\n",
    "    project_root = os.path.normpath(project_root)\n",
    "    \n",
    "    config_path = os.path.join(project_root, 'config.json')\n",
    "\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found at expected location: {config_path}\")\n",
    "\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    return config, project_root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba9cd3e-01db-4993-be31-0768e4814084",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, project_root = load_config()\n",
    "\n",
    "group_path_enterprise = os.path.normpath(os.path.join(project_root, config[\"data_directory\"], config[\"file_paths_groups_v15\"][\"enterprise\"]))\n",
    "group_path_mobile = os.path.normpath(os.path.join(project_root, config[\"data_directory\"], config[\"file_paths_groups_v15\"][\"mobile\"]))\n",
    "group_path_ics = os.path.normpath(os.path.join(project_root, config[\"data_directory\"], config[\"file_paths_groups_v15\"][\"ics\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c39165-94ed-4119-b250-cd64c994180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect file paths into a list\n",
    "group_file_paths = [group_path_enterprise, group_path_mobile, group_path_ics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42647cd2-232b-4560-a72e-559c63c25c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_group_mapping_from_config(groups_file_paths, mapping_type='software'):\n",
    "    \"\"\"\n",
    "    Reads multiple Excel files for APT groups and their software or technique mappings.\n",
    "    Merges all mappings and provides usage statistics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    groups_file_paths : dict\n",
    "        Dictionary of attack type -> Excel file path.\n",
    "    mapping_type : str\n",
    "        Either 'software' or 'techniques' to select the appropriate sheet.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping of APT group IDs to names and software/techniques used.\n",
    "    int\n",
    "        Number of unique APT groups.\n",
    "    int\n",
    "        Number of unique software or techniques used.\n",
    "    dict\n",
    "        Statistical summary: mean, median, mode, max/min counts and groups.\n",
    "    \"\"\"\n",
    "    # Select sheet based on mapping_type\n",
    "    if mapping_type == 'software':\n",
    "        sheet_name = 'associated software'\n",
    "    elif mapping_type == 'techniques':\n",
    "        sheet_name = 'techniques used'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mapping_type. Choose either 'software' or 'techniques'.\")\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    # Iterate over files and load data\n",
    "    for file_path in groups_file_paths:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        try:\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Sheet '{sheet_name}' not found in {file_path}\")\n",
    "\n",
    "        required_columns = {'source name', 'source ID', 'target ID'}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Missing required columns in {file_path}: {df.columns.tolist()}\")\n",
    "\n",
    "        # For techniques, also require the target name\n",
    "        if mapping_type == 'techniques' and 'target name' not in df.columns:\n",
    "            raise ValueError(f\"Missing 'target name' column in {file_path} for techniques mapping\")\n",
    "\n",
    "        # Add the target name column if mapping_type is 'techniques'\n",
    "        all_rows.append(df[['source name', 'source ID', 'target ID', 'target name', 'target ref']] \n",
    "                         if mapping_type == 'software' else df[['source name', 'source ID', 'target ID', 'target name']])\n",
    "\n",
    "    # Combine all rows from different files\n",
    "    merged_df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # Build the mapping: group ID -> {name, targets, technique names}\n",
    "    apt_map = {}\n",
    "    grouped = merged_df.groupby('source ID')\n",
    "\n",
    "    for group_id, group_df in grouped:\n",
    "        group_name = group_df['source name'].iloc[0]\n",
    "        targets = group_df['target ID'].dropna().unique().tolist()\n",
    "\n",
    "        # For techniques mapping, we need to include the technique names as well\n",
    "        if mapping_type == 'techniques':\n",
    "            technique_names = group_df['target name'].fillna('').unique().tolist()\n",
    "            apt_map[group_id] = {\n",
    "                'name': group_name,\n",
    "                'items': targets,\n",
    "                'technique name': technique_names\n",
    "            }\n",
    "        elif mapping_type == 'software':\n",
    "            # For software, we continue with the existing logic\n",
    "            types = group_df['target ref'].apply(lambda x: 'Malware' if 'malware' in str(x).lower() else 'Tool')\n",
    "            type_mapping = types.value_counts().to_dict()\n",
    "\n",
    "            apt_map[group_id] = {\n",
    "                'name': group_name,\n",
    "                'items': targets,\n",
    "                'type': type_mapping\n",
    "            }\n",
    "\n",
    "    # Count per group (number of unique targets)\n",
    "    item_counts = merged_df.groupby('source ID')['target ID'].nunique()\n",
    "\n",
    "    # Stats\n",
    "    mean_count = item_counts.mean()\n",
    "    median_count = item_counts.median()\n",
    "    try:\n",
    "        mode_count = mode(item_counts)\n",
    "    except:\n",
    "        mode_count = 'No unique mode'\n",
    "\n",
    "    max_apt_group = item_counts.idxmax()\n",
    "    max_count = item_counts[max_apt_group]\n",
    "\n",
    "    min_apt_group = item_counts.idxmin()\n",
    "    min_count = item_counts[min_apt_group]\n",
    "\n",
    "    stats = {\n",
    "        'mean_count': mean_count,\n",
    "        'median_count': median_count,\n",
    "        'mode_count': mode_count,\n",
    "        'max_count': max_count,\n",
    "        'max_apt_group': max_apt_group,\n",
    "        'min_count': min_count,\n",
    "        'min_apt_group': min_apt_group\n",
    "    }\n",
    "\n",
    "    return apt_map, merged_df['source ID'].nunique(), merged_df['target ID'].nunique(), stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7513b410-2796-464c-979d-35b740f70e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example call to the function for techniques mapping\n",
    "techniques_map, unique_groups_technique, unique_techniques, stats_technique = apt_group_mapping_from_config(\n",
    "    group_file_paths, mapping_type='techniques'\n",
    ")\n",
    "\n",
    "# Example call to the function for software mapping\n",
    "software_map, unique_groups_software, unique_software, stats_software = apt_group_mapping_from_config(\n",
    "    group_file_paths, mapping_type='software'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c4704eb-8aaa-42e0-bf7b-219bc2043e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138,\n",
       " 509,\n",
       " {'mean_count': np.float64(6.753623188405797),\n",
       "  'median_count': np.float64(4.0),\n",
       "  'mode_count': 2,\n",
       "  'max_count': np.int64(48),\n",
       "  'max_apt_group': 'G0016',\n",
       "  'min_count': np.int64(1),\n",
       "  'min_apt_group': 'G0002'})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#techniques_map.get(\"G0138\n",
    "unique_groups_software, unique_software, stats_software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6e69ab1-f94c-4a82-8c95-1bbc5b6663f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups_with_unique_techniques(technique_map):\n",
    "    \"\"\"\n",
    "    Counts how many APT groups have at least one unique technique \n",
    "    (i.e., not used by any other group).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    technique_map : dict\n",
    "        Mapping of group ID to their techniques.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A summary including:\n",
    "        - number of groups with unique techniques\n",
    "        - group-to-unique-techniques map (up to 10 sample groups)\n",
    "        - top 10 most common techniques (optional)\n",
    "    \"\"\"\n",
    "    from collections import defaultdict, Counter\n",
    "\n",
    "    technique_to_groups = defaultdict(set)\n",
    "    group_to_techs = {}\n",
    "\n",
    "    # Build reverse map: technique -> groups\n",
    "    for group_id, data in technique_map.items():\n",
    "        techniques = data.get(\"items\", [])\n",
    "        group_to_techs[group_id] = set(techniques)\n",
    "        for tech in techniques:\n",
    "            technique_to_groups[tech].add(group_id)\n",
    "\n",
    "    # Identify unique techniques per group\n",
    "    unique_per_group = {}\n",
    "    for group_id, techs in group_to_techs.items():\n",
    "        unique_techs = {t for t in techs if len(technique_to_groups[t]) == 1}\n",
    "        if unique_techs:\n",
    "            unique_per_group[group_id] = list(unique_techs)\n",
    "\n",
    "    # Top 10 most used techniques (optional)\n",
    "    technique_usage = Counter()\n",
    "    for tech, groups in technique_to_groups.items():\n",
    "        technique_usage[tech] = len(groups)\n",
    "    top_10_common_techniques = technique_usage.most_common(10)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nNumber of groups with unique techniques: {len(unique_per_group)}\")\n",
    "    print(\"\\nExample groups with unique techniques:\")\n",
    "    for group_id, uniq_techs in list(unique_per_group.items())[:5]:  # limit to 5\n",
    "        print(f\"  Group {group_id} ({technique_map[group_id]['name']}):\")\n",
    "        for tech in uniq_techs[:5]:  # show up to 5 techniques\n",
    "            print(f\"    - {tech}\")\n",
    "        if len(uniq_techs) > 5:\n",
    "            print(f\"    ... and {len(uniq_techs) - 5} more\")\n",
    "\n",
    "    return {\n",
    "        \"num_groups_with_unique_techniques\": len(unique_per_group),\n",
    "        \"unique_techniques_per_group\": unique_per_group,\n",
    "        \"top_10_common_techniques\": top_10_common_techniques\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4f08733-2f89-4aa3-a8be-04271910c40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of groups with unique techniques: 111\n",
      "\n",
      "Example groups with unique techniques:\n",
      "  Group G0001 (Axiom):\n",
      "    - S0672\n",
      "    - S0009\n",
      "  Group G0003 (Cleaver):\n",
      "    - S0056\n",
      "    - S0004\n",
      "  Group G0004 (Ke3chang):\n",
      "    - S0439\n",
      "    - S0227\n",
      "    - S0691\n",
      "    - S0280\n",
      "  Group G0005 (APT12):\n",
      "    - S0015\n",
      "    - S0003\n",
      "  Group G0006 (APT1):\n",
      "    - S0109\n",
      "    - S0026\n",
      "    - S0123\n",
      "    - S0025\n",
      "    - S0119\n",
      "    ... and 4 more\n"
     ]
    }
   ],
   "source": [
    "#technique_stats = groups_with_unique_techniques(techniques_map)\n",
    "software_stats = groups_with_unique_techniques(software_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "833d57e7-4c1c-4b38-8c36-efc3670209cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S0002', 46),\n",
       " ('S0029', 31),\n",
       " ('S0039', 30),\n",
       " ('S0154', 24),\n",
       " ('S0363', 15),\n",
       " ('S0012', 14),\n",
       " ('S0013', 13),\n",
       " ('S0097', 13),\n",
       " ('S0100', 13),\n",
       " ('S0349', 12)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_stats[\"top_10_common_techniques\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46605e8-cb60-433d-b6d2-e8eafce0738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_metadata(metadata_path):\n",
    "    \"\"\"\n",
    "    Loads the group metadata JSON file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata_path : str\n",
    "        Path to the JSON file containing group metadata.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Group metadata loaded from the file.\n",
    "    \"\"\"\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b8f0cf-4f7b-41d3-a3c2-0004740a32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to group_metadata.json\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))  # move up from notebooks/\n",
    "file_mitre_ttp = os.path.join(project_root, \"group_analysis_json_outputs\", \"MITRE_ttp_group_analysis.json\")\n",
    "file_malpedia_ttp = os.path.join(project_root, \"group_analysis_json_outputs\", \"Malpedia_ttp_group_analysis.json\")\n",
    "file_malpedia_software = os.path.join(project_root, \"group_analysis_json_outputs\", \"malpedia_actor_to_software_map.json\")\n",
    "\n",
    "# Load the file\n",
    "mitre_ttp_metadata = load_json_metadata(file_mitre_ttp)\n",
    "malpedia_ttp_metadata = load_json_metadata(file_malpedia_ttp)\n",
    "malpedia_software_metadata = load_json_metadata(file_malpedia_software)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8660e740-fd6e-4b46-9ec5-eea25303d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_group_sets(techniques_map, ttp_data):\n",
    "    \"\"\"\n",
    "    Compare group sets between techniques_map (MITRE) and ttp_data (Threat Reports).\n",
    "    \n",
    "    Prints:\n",
    "    - Total groups in techniques_map\n",
    "    - Total groups in ttp_data\n",
    "    - Intersection (common groups)\n",
    "    - Groups only in techniques_map\n",
    "    - Groups only in ttp_data\n",
    "    \"\"\"\n",
    "    techniques_groups = set(techniques_map.keys())\n",
    "    ttp_groups = set(ttp_data.keys())\n",
    "\n",
    "    intersection = techniques_groups & ttp_groups\n",
    "    only_in_techniques = techniques_groups - ttp_groups\n",
    "    only_in_ttp_data = ttp_groups - techniques_groups\n",
    "\n",
    "    print(f\"Total groups in techniques_map: {len(techniques_groups)}\")\n",
    "    print(f\"Total groups in ttp_data (Threat Reports): {len(ttp_groups)}\")\n",
    "    print(f\"Groups present in both (intersection): {len(intersection)}\\n\")\n",
    "\n",
    "    print(f\"Groups only in techniques_map (not observed in reports): {len(only_in_techniques)}\")\n",
    "    print(f\"Groups only in ttp_data (not in MITRE mapping): {len(only_in_ttp_data)}\\n\")\n",
    "\n",
    "    return {\n",
    "        \"techniques_groups\": techniques_groups,\n",
    "        \"ttp_groups\": ttp_groups,\n",
    "        \"intersection\": intersection,\n",
    "        \"only_in_techniques\": only_in_techniques,\n",
    "        \"only_in_ttp_data\": only_in_ttp_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205d2ed4-afc1-453f-a38f-9dd7bffe312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total groups in techniques_map: 148\n",
      "Total groups in ttp_data (Threat Reports): 63\n",
      "Groups present in both (intersection): 62\n",
      "\n",
      "Groups only in techniques_map (not observed in reports): 86\n",
      "Groups only in ttp_data (not in MITRE mapping): 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_stats = compare_group_sets(techniques_map, mitre_ttp_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "773d4969-f6b2-4ac8-b682-f5f2b24cfa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_techniques_map_with_observed_ttps(techniques_map, ttp_data):\n",
    "    \"\"\"\n",
    "    Enhances the techniques_map by adding new TTPs from ttp_data.\n",
    "    Renames 'items' key to 'techniques' for better clarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    techniques_map : dict\n",
    "        Original techniques mapping from MITRE ATT&CK Excel sheets.\n",
    "    ttp_data : dict\n",
    "        Observed TTPs from threat report hashes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        - Updated techniques_map with observed TTPs added.\n",
    "        - A diff dictionary showing newly added TTPs per group.\n",
    "    \"\"\"\n",
    "    enhanced_map = {}\n",
    "\n",
    "    diff_per_group = {}\n",
    "\n",
    "    for group_id, group_info in techniques_map.items():\n",
    "        # Rename 'items' to 'techniques'\n",
    "        enhanced_map[group_id] = {\n",
    "            \"name\": group_info.get(\"name\", \"\"),\n",
    "            \"techniques\": group_info.get(\"items\", []),  # use existing items under new key\n",
    "            \"technique name\": group_info.get(\"technique name\", [])\n",
    "        }\n",
    "\n",
    "    for group_id, threat_data in ttp_data.items():\n",
    "        observed_ttps = set()\n",
    "        for hash_entry in threat_data.get('hashes', []):\n",
    "            observed_ttps.update(t.upper().strip() for t in hash_entry.get('ttps', []))\n",
    "\n",
    "        if group_id in enhanced_map:\n",
    "            official_ttps = set(t.upper().strip() for t in enhanced_map[group_id].get('techniques', []))\n",
    "            new_ttps = observed_ttps - official_ttps\n",
    "\n",
    "            if new_ttps:\n",
    "                enhanced_map[group_id][\"techniques\"].extend(new_ttps)\n",
    "                diff_per_group[group_id] = list(new_ttps)\n",
    "\n",
    "        else:\n",
    "            # Group missing in MITRE, create new entry\n",
    "            enhanced_map[group_id] = {\n",
    "                \"name\": \"\",\n",
    "                \"techniques\": list(observed_ttps),\n",
    "                \"technique name\": []\n",
    "            }\n",
    "            diff_per_group[group_id] = list(observed_ttps)\n",
    "\n",
    "    return enhanced_map, diff_per_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b076d18-4147-490c-95ee-f2a344c18ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_diff_summary(diff_per_group, techniques_map):\n",
    "    \"\"\"\n",
    "    Prints a summary of newly added techniques per group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    diff_per_group : dict\n",
    "        Mapping of group ID to list of newly added TTPs.\n",
    "    techniques_map : dict\n",
    "        Mapping to get the group names.\n",
    "    \"\"\"\n",
    "    if not diff_per_group:\n",
    "        print(\"No new TTPs were added.\")\n",
    "        return\n",
    "\n",
    "    print(f\"New TTPs added to {len(diff_per_group)} groups:\\n\")\n",
    "    for group_id, new_ttps in diff_per_group.items():\n",
    "        group_name = techniques_map.get(group_id, {}).get(\"name\", \"Unknown Group\")\n",
    "        print(f\"Group {group_id} ({group_name}): {len(new_ttps)} new TTPs\")\n",
    "        for ttp in new_ttps[:5]:  # show up to 5 per group\n",
    "            print(f\"  - {ttp}\")\n",
    "        if len(new_ttps) > 5:\n",
    "            print(f\"  ... and {len(new_ttps) - 5} more\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6849c24e-e91c-476b-8233-4e9b323461ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_techniques_map, diff_per_group = enhance_techniques_map_with_observed_ttps(techniques_map, mitre_ttp_metadata)\n",
    "\n",
    "#print_diff_summary(diff_per_group, enhanced_techniques_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1a713c-4866-4a0b-b69e-19cfb66b78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize group names\n",
    "def normalize_group_name(name):\n",
    "    # Convert to lowercase for case-insensitive comparison\n",
    "    name = name.lower().strip()\n",
    "\n",
    "    # Remove 'team' from names like 'Sandworm Team'\n",
    "    if name.endswith(' team'):\n",
    "        name = name.replace(' team', '')\n",
    "\n",
    "    # Replace 'threat group-' with 'tg-' (e.g., 'Threat Group-1314' -> 'TG-1314')\n",
    "    name = re.sub(r'threat group[- ]', 'tg-', name)\n",
    "\n",
    "    # Remove 'temp.' or similar prefixes (e.g., 'Temp.Pittytiger' -> 'Pittytiger')\n",
    "    name = re.sub(r'^temp[\\. ]+', '', name)\n",
    "\n",
    "    # Normalize spaces and dots (e.g., 'pitty tiger' == 'pitty.tiger')\n",
    "    name = re.sub(r'[\\. ]+', ' ', name)\n",
    "\n",
    "    # Remove common suffixes like 'framework' or 'group' (e.g., 'Inception Framework' -> 'Inception')\n",
    "    name = re.sub(r' (framework|group)$', '', name)\n",
    "\n",
    "    # Standardize 'Confucius' and 'Confucious' to 'confucius'\n",
    "    name = re.sub(r'confucious', 'confucius', name)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2bd49c9-1afc-4f14-bae3-725c804e3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_techniques_software_map_with_group_aliases(techniques_map, group_metadata, software_map):\n",
    "    \"\"\"\n",
    "    Builds an enhanced techniques map with MITRE and Malpedia metadata, and software data.\n",
    "\n",
    "    Handles the following cases:\n",
    "    - Group has techniques and software → merge both.\n",
    "    - Group has techniques but no software → add empty attack_software key.\n",
    "    - Group only in software_map → create entry with techniques empty.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    techniques_map : dict\n",
    "        Technique mappings per group.\n",
    "    group_metadata : dict\n",
    "        Metadata like names and aliases for groups.\n",
    "    software_map : dict\n",
    "        Software used by each group ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Enhanced mapping containing MITRE & Malpedia metadata, techniques, and software.\n",
    "    \"\"\"\n",
    "    enhanced_map = {}\n",
    "    all_group_ids = set(techniques_map.keys()).union(set(software_map.keys()))\n",
    "    missing_metadata_groups = []\n",
    "\n",
    "    for group_id in all_group_ids:\n",
    "        technique_data = techniques_map.get(group_id, {})\n",
    "        software_data = software_map.get(group_id, {})\n",
    "        metadata = group_metadata.get(group_id, {})\n",
    "\n",
    "        if not metadata:\n",
    "            missing_metadata_groups.append(group_id)\n",
    "\n",
    "        enhanced_map[group_id] = {\n",
    "            'mitre name': metadata.get('MITRE Group Name', ''),\n",
    "            'mitre alias': metadata.get('MITRE Associated Names', []),\n",
    "            'malpedia name': metadata.get('Malpedia Actor Name', ''),\n",
    "            'malpedia alias': metadata.get('Malpedia Aliases', []),\n",
    "            'attack techniques': technique_data.get('techniques', []),\n",
    "            'technique name': technique_data.get('technique name', []),\n",
    "            'attack software': software_data.get('items', [])  # empty list if not present\n",
    "        }\n",
    "\n",
    "    if missing_metadata_groups:\n",
    "        print(f\"Warning: Metadata not found for {len(missing_metadata_groups)} groups.\")\n",
    "        print(f\"Examples: {', '.join(missing_metadata_groups[:10])}\")\n",
    "\n",
    "    return enhanced_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fbd2d15-945d-42b6-bdcd-cb84281baacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to group_metadata.json\n",
    "metadata_file_group_name_map = os.path.join(project_root, \"attack_malpedia_intersection\", \"attack_malpedia_group_mapping.json\")\n",
    "\n",
    "# Load metadata\n",
    "group_name_metadata = load_json_metadata(metadata_file_group_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "408640e0-a965-4e06-a3ba-ba1b57d2e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Metadata not found for 7 groups.\n",
      "Examples: G0089, G0140, G0124, G0028, G1027, G0108, G0114\n"
     ]
    }
   ],
   "source": [
    "enhanced_techniques_software_alias_map = enhanced_techniques_software_map_with_group_aliases(enhanced_techniques_map, group_name_metadata, software_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90f511be-9e73-4720-b5b7-298265bce8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enhanced_techniques_software_alias_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d9cbf7e-fe97-4469-9900-ec6aa08021b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_to_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Dumps data to a JSON file in the specified output folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dict\n",
    "        The data to be written to the JSON file.\n",
    "    output_folder : str\n",
    "        The folder where the JSON file will be saved.\n",
    "    filename : str\n",
    "        The name of the output JSON file (including .json extension).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the data was successfully written to the file, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file {file_path}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5342e2b5-b101-462b-b6bb-70277cc78e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "json_output_data_dir = os.path.join(base_dir, \"intermediate_json_outputs\")\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(json_output_data_dir, exist_ok=True)\n",
    "filename = \"attack_group_software_profile.json\"\n",
    "# Full path to the output file\n",
    "file_path = os.path.join(json_output_data_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "916a40f2-e555-4768-a308-2f140f6b7fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_to_json(enhanced_techniques_software_alias_map, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e5109c-bc10-43b2-9718-87ef8a023c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_malpedia_ttps_software(enhanced_techniques_software_alias_map, malpedia_ttps, malpedia_softwares):\n",
    "    \"\"\"\n",
    "    Updates enhanced_techniques_software_alias_map with Malpedia techniques and software per group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    enhanced_techniques_software_alias_map : dict\n",
    "        Dictionary mapping group IDs to their MITRE and Malpedia metadata.\n",
    "    malpedia_ttps : dict\n",
    "        Dictionary containing TTPs (techniques) per actor name from Malpedia.\n",
    "    malpedia_softwares : dict\n",
    "        Dictionary containing software per actor name from Malpedia.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Updated enhanced_techniques_software_alias_map including Malpedia techniques and software.\n",
    "    \"\"\"\n",
    "\n",
    "    unmatched_malpedia_names = {\n",
    "        \"actor\": [],\n",
    "        \"family\": [],\n",
    "        \"attribution\": []\n",
    "    }\n",
    "    unmatched_software_groups = []\n",
    "\n",
    "    count_technique = 0\n",
    "    count_software = 0\n",
    "\n",
    "    # Build normalized group name index for fast lookups\n",
    "    group_name_index = {}\n",
    "    for group_id, group_info in enhanced_techniques_software_alias_map.items():\n",
    "        names = [\n",
    "            normalize_group_name(group_info.get('mitre name', '')),\n",
    "            normalize_group_name(group_info.get('malpedia name', ''))\n",
    "        ] + [\n",
    "            normalize_group_name(alias) for alias in group_info.get('mitre alias', []) + group_info.get('malpedia alias', [])\n",
    "        ]\n",
    "        for name in names:\n",
    "            group_name_index[name] = group_id\n",
    "\n",
    "        # Ensure empty lists exist for keys\n",
    "        enhanced_techniques_software_alias_map[group_id].setdefault('malpedia techniques', [])\n",
    "        enhanced_techniques_software_alias_map[group_id].setdefault('malpedia software', [])\n",
    "\n",
    "    # Process techniques\n",
    "    for malpedia_group, malpedia_data in malpedia_ttps.items():\n",
    "        norm_name = normalize_group_name(malpedia_group)\n",
    "        group_id = group_name_index.get(norm_name)\n",
    "\n",
    "        # Extract all TTPs\n",
    "        all_ttps = set()\n",
    "        for hash_entry in malpedia_data.get('hashes', []):\n",
    "            all_ttps.update(hash_entry.get('ttps', []))\n",
    "\n",
    "        if group_id:\n",
    "            enhanced_techniques_software_alias_map[group_id]['malpedia techniques'] = list(all_ttps)\n",
    "            count_technique += 1\n",
    "        else:\n",
    "            for url_entry in malpedia_data.get(\"urls\", []):\n",
    "                source = url_entry.get(\"source\")\n",
    "                if source in unmatched_malpedia_names:\n",
    "                    unmatched_malpedia_names[source].append(norm_name)\n",
    "                    break\n",
    "\n",
    "    # Process software\n",
    "    for malpedia_group, software_list in malpedia_softwares.items():\n",
    "        norm_name = normalize_group_name(malpedia_group)\n",
    "        group_id = group_name_index.get(norm_name)\n",
    "\n",
    "        if group_id:\n",
    "            enhanced_techniques_software_alias_map[group_id]['malpedia software'] = software_list\n",
    "            count_software += 1\n",
    "        else:\n",
    "            unmatched_software_groups.append(norm_name)\n",
    "\n",
    "    # Report unmatched Malpedia technique groups by source\n",
    "    for source_category, unmatched_groups in unmatched_malpedia_names.items():\n",
    "        if unmatched_groups:\n",
    "            print(f\"Warning: {len(unmatched_groups)} Malpedia groups in '{source_category}' not matched to any MITRE group.\")\n",
    "            print(f\"Examples: {', '.join(unmatched_groups[:10])} ...\")\n",
    "\n",
    "    # Report unmatched software groups\n",
    "    if unmatched_software_groups:\n",
    "        print(f\"Warning: {len(unmatched_software_groups)} Malpedia software groups not matched to any MITRE group.\")\n",
    "        print(f\"Examples: {', '.join(unmatched_software_groups[:10])} ...\")\n",
    "\n",
    "    print(f\"Total matches with Malpedia techniques: {count_technique}\")\n",
    "    print(f\"Total matches with Malpedia software: {count_software}\")\n",
    "\n",
    "    return enhanced_techniques_software_alias_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bcfd69a-3403-49ac-94ea-77ef30a95134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 74 Malpedia groups in 'actor' not matched to any MITRE group.\n",
      "Examples: xdspy, dust storm, honeybee, circus spider, ghostemperor, viceroy tiger, red dev 17, night dragon, prophet spider, mallard spider ...\n",
      "Warning: 375 Malpedia groups in 'family' not matched to any MITRE group.\n",
      "Examples: elf acidrain, win especter, win owlproxy, win hakbit, js jeniva, win glupteba, win supernova, win anubis_loader, win darkside, elf blackmatter ...\n",
      "Warning: 21 Malpedia groups in 'attribution' not matched to any MITRE group.\n",
      "Examples: unknown, sweed, riddle spider, scully spider, buhtrap, gold dupont, henbox, [unnamed group], gold winter, apt 29 ...\n",
      "Warning: 125 Malpedia software groups not matched to any MITRE group.\n",
      "Examples: poison carp, henbox, yanbian gang, apt-c-27, apt-c-35, ta413, apt 22, void manticore, red menshen, gelsemium ...\n",
      "Total matches with Malpedia techniques: 121\n",
      "Total matches with Malpedia software: 122\n"
     ]
    }
   ],
   "source": [
    "complete_technique_map = update_with_malpedia_ttps_software(enhanced_techniques_software_alias_map, malpedia_ttp_metadata, malpedia_software_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a42087c3-6e95-42a5-b238-3616c0a61bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(complete_technique_map.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1a59fac-d3fa-4c23-9fde-d9bbdd4ac5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591, 152, 247)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(malpedia_ttp_metadata), len(complete_technique_map), len(malpedia_software_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67da0203-32bc-46f1-b01a-9f322411b068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"malpedia_attack_group_software_profile.json\"\n",
    "# Full path to the output file\n",
    "file_path = os.path.join(json_output_data_dir, filename)\n",
    "dump_to_json(enhanced_techniques_software_alias_map, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4db79d-c684-446f-a974-6b74a1ae87f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total groups found: 152\n"
     ]
    }
   ],
   "source": [
    "# URL of the MITRE ATT&CK Groups page\n",
    "#url = \"https://attack.mitre.org/groups/\"\n",
    "url = \"https://attack.mitre.org/versions/v15/groups/\"\n",
    "\n",
    "# Send a GET request to fetch the page content\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Use regular expression to find all group IDs (e.g., G0001, G1000)\n",
    "    group_ids = re.findall(r'G\\d{4}', response.text)\n",
    "    unique_group_ids = sorted(set(group_ids))\n",
    "    \n",
    "    print(f\"Total groups found: {len(unique_group_ids)}\")\n",
    "    #print(\"Group IDs:\")\n",
    "    #for gid in unique_group_ids:\n",
    "    #    print(gid)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd5101-4e03-4895-877d-38c352277747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'parsed_group_ids' is a set of group IDs from your Excel data\n",
    "parsed_group_ids = set(techniques_map.keys())\n",
    "\n",
    "# 'unique_group_ids' is the set obtained from the MITRE website\n",
    "missing_in_parsed = set(unique_group_ids) - parsed_group_ids\n",
    "extra_in_parsed = parsed_group_ids - set(unique_group_ids)\n",
    "\n",
    "print(\"Group IDs missing in parsed data:\", missing_in_parsed)\n",
    "print(\"Unexpected group IDs in parsed data:\", extra_in_parsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
