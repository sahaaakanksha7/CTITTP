{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f516d4-d62b-41ad-b658-8ff365b39220",
   "metadata": {},
   "outputs": [],
   "source": [
    "##17 hashes are duplicated i.e, have duplicate URLs and have been downled as a same report with same TTPs as two different hashes ->\n",
    "##120 - 17 is the true ground truth\n",
    "# Function to find unique hashes with URLs and track removed hashes\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3c71e2-8fcc-4961-80ec-47bcf4e24058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Locate and load config.json from one level up\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "config_path = os.path.normpath(os.path.join(parent_dir, 'config.json'))\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Step 2: Build absolute path prefix based on where config.json was loaded from\n",
    "config_dir = os.path.dirname(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0b61c8-5f29-4bae-83b4-929168727b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl_to_dict(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and converts it into a list of dictionaries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The path to the JSONL file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        A list of dictionaries where each dictionary represents one line in the JSONL file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Parse each line into a dictionary and append to the list\n",
    "            data.append(json.loads(line))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c20d1b-8153-4bc3-ac09-948b66b53623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MITRE JSONL entries in enterprise: 1417\n",
      "Total MITRE JSONL entries in mobile/ics:: 25\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "mitre_enterprise_jsonl = os.path.normpath(os.path.join(config_dir, config[\"jsonl_files\"][\"MITRE_enterprise\"]))\n",
    "mitre_mobileics_jsonl = os.path.normpath(os.path.join(config_dir, config[\"jsonl_files\"][\"MITRE_mobileics\"]))\n",
    "combined_json_files = [mitre_enterprise_jsonl, mitre_mobileics_jsonl]\n",
    "\n",
    "data = read_jsonl_to_dict(mitre_enterprise_jsonl)\n",
    "print(f\"Total MITRE JSONL entries in enterprise: {len(data)}\")\n",
    "data = read_jsonl_to_dict(mitre_mobileics_jsonl)\n",
    "print(f\"Total MITRE JSONL entries in mobile/ics:: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d5c340-c5b7-4bf2-8708-57d4ccc9134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_folders(folder_path):\n",
    "    \"\"\"\n",
    "    Count the number of files in the given folder paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        The primary folder containing the files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The total count of files in both folders.\n",
    "    \"\"\"\n",
    "    # Count files in the primary folder\n",
    "    primary_folder_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "\n",
    "    # Calculate the total count of files \n",
    "    total_files_count = len(primary_folder_files) \n",
    "\n",
    "    print(f\"Total number of files: {total_files_count}\")\n",
    "\n",
    "    return total_files_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ac22b2-77b1-4c04-b9cb-1764cc486260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 920\n",
      "Total number of files: 122\n"
     ]
    }
   ],
   "source": [
    "mitre_ttp_path = os.path.normpath(os.path.join(config_dir, config[\"directory_paths_ioc\"][\"TTP_MITRE\"]))\n",
    "mitre_threatreport_path = os.path.normpath(os.path.join(config_dir, config[\"threat_report_directories\"][\"MITRE\"]))\n",
    "\n",
    "# Get total file count\n",
    "total_reports = count_files_in_folders(mitre_threatreport_path)\n",
    "total_reports_ttps = count_files_in_folders(mitre_ttp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33522473-2764-47dc-8a4e-e91870d481d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cumulative_unique_ttps(folder_path):\n",
    "    \"\"\"\n",
    "    Count cumulative unique TTP IDs across all files in the given folder paths.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the first folder.\n",
    "    secondary_folder_path : str\n",
    "        Path to the second folder.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        A set of unique TTP IDs found in both folders.\n",
    "    \"\"\"\n",
    "    unique_ttps = set()\n",
    "\n",
    "    # Regex pattern to capture full TTP IDs (e.g., T1003, T1003.001)\n",
    "    ttp_pattern = re.compile(r'\\bT\\d{4}(?:\\.\\d+)?\\b')\n",
    "\n",
    "    # Loop through both folders\n",
    "    for folder in [folder_path]:\n",
    "        for file_name in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "\n",
    "            # Skip hidden or backup files\n",
    "            if file_name.startswith('_'):\n",
    "                print(f\"Skipping hidden or backup file: {file_name}\")\n",
    "                continue\n",
    "\n",
    "            if os.path.isfile(file_path):\n",
    "                #print(f\"Reading TTPs from file: {file_name}\")\n",
    "                try:\n",
    "                    # Open the file and check each line for TTP patterns\n",
    "                    with open(file_path, 'r', errors='ignore') as file:\n",
    "                        for line in file:\n",
    "                            # Find all TTP IDs in the line and add them directly to the cumulative set\n",
    "                            matches = ttp_pattern.findall(line)\n",
    "                            unique_ttps.update(matches)  # Add each unique TTP ID found in the line\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_name}: {e}\")\n",
    "    \n",
    "    return unique_ttps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40cd1a55-1d93-4636-8cd2-6d0cb23b975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Unique TTPs found: 470\n"
     ]
    }
   ],
   "source": [
    "unique_ttps = count_cumulative_unique_ttps(mitre_ttp_path)\n",
    "\n",
    "# Display the unique TTPs\n",
    "print(f\"Cumulative Unique TTPs found: {len(unique_ttps)}\")\n",
    "#for ttp in unique_ttps:\n",
    "#   print(ttp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649adb7-db43-49f2-a5e7-f8c00dbb8a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
