{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "253a930c-ee95-491e-bf32-7bec284d7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_file_hashes(folder_path):\n",
    "    \"\"\"\n",
    "    Extracts file hashes (part before .download.iocs) from filenames in a folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        The path to the folder.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of file hashes extracted from the filenames.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # List all files in the specified folder and keep only the hashes\n",
    "        file_hashes = [\n",
    "            file.split('.download.iocs')[0] \n",
    "            for file in os.listdir(folder_path) \n",
    "            if os.path.isfile(os.path.join(folder_path, file))\n",
    "        ]\n",
    "        return file_hashes\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08d9aa69-03ab-425b-8b38-6f1c88f5c70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to the folder\n",
    "folder_path = r\"C:\\Users\\Aakanksha Saha\\Documents\\CTI_downloads\\downloads\\20241008_downloads\\iocs2\"\n",
    "# Get and print the list of file hashes\n",
    "file_hashes = get_file_hashes(folder_path)\n",
    "#print(\"File hashes:\", file_hashes)\n",
    "len(file_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27f5a05f-2da2-4470-9c3f-dad7a57d3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from PyPDF2.errors import WrongPasswordError\n",
    "\n",
    "def read_cti_reports(folder_path, file_hashes, password=None):\n",
    "    \"\"\"\n",
    "    Reads the CTI report files with .download extension for each hash in file_hashes. Handles text files and encrypted PDFs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        The path to the folder containing the CTI reports.\n",
    "    file_hashes : list\n",
    "        A list of file hashes to look for and read.\n",
    "    password : str, optional\n",
    "        Password to decrypt encrypted PDF files, by default None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary where keys are file hashes and values are the file content or error message.\n",
    "    \"\"\"\n",
    "    report_results = {}\n",
    "\n",
    "    for file_hash in file_hashes:\n",
    "        file_path = os.path.join(folder_path, f\"{file_hash}.download\")\n",
    "\n",
    "        # Check if the file exists and is readable\n",
    "        if os.path.exists(file_path) and os.path.isfile(file_path):\n",
    "            try:\n",
    "                # Attempt to read the file as UTF-8 text\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "\n",
    "                parsed_data = parse_cti_report(content)  # This function parses the report\n",
    "                report_results[file_hash] = parsed_data\n",
    "\n",
    "            except UnicodeDecodeError:\n",
    "                # If a UnicodeDecodeError occurs, the file might be a binary PDF\n",
    "                #print(f\"Error reading file as text. Attempting to read as PDF: {file_path}\")\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "                        # Handle encrypted PDF if a password is required\n",
    "                        if pdf_reader.is_encrypted:\n",
    "                            try:\n",
    "                                pdf_reader.decrypt(password or \"\")\n",
    "                            except WrongPasswordError:\n",
    "                                report_results[file_hash] = {\"error\": \"Failed to decrypt PDF, wrong password.\"}\n",
    "                                continue  # Skip to next file hash\n",
    "\n",
    "                        text = \"\"\n",
    "                        # Extract text from each page of the PDF\n",
    "                        for page_num in range(len(pdf_reader.pages)):\n",
    "                            text += pdf_reader.pages[page_num].extract_text()\n",
    "\n",
    "                        parsed_pdfdata = parse_pdf_cti_report(text)\n",
    "                        report_results[file_hash] = parsed_pdfdata\n",
    "\n",
    "                except Exception as e:\n",
    "                    report_results[file_hash] = {\"error\": f\"Failed to read file as PDF. Error: {e}\"}\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle any other errors during the file read process\n",
    "                report_results[file_hash] = {\"error\": f\"Error reading file: {e}\"}\n",
    "\n",
    "        else:\n",
    "            report_results[file_hash] = {\"error\": \"File does not exist or is not readable.\"}\n",
    "\n",
    "    return report_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd64fbf4-aba8-4262-808d-e7896153acb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reports processed: 120\n",
      "\n",
      "File Hash: 03d45314206806cf6f36726529032c5356da95c23695ae5017ba3e11eeafac78\n",
      "File Hash: 0bf616f861446bbe94673779d6ca1f2fa6eda49681c709b06054c670516beb43\n",
      "File Hash: 0ce5ca914f9c8c456f587147cc528ba8e441192d7dba157ea59eaece0a9d19a5\n",
      "File Hash: 1558cf13032850ebeab8a86e61e3876c0fcbf627df5f4ca4dc3d32772090a134\n",
      "File Hash: 17c02186b93909f891fb341198c5a37b9469539b76acff00898864d4ad8745a1\n",
      "File Hash: 1ba216c39a5dd90c9f7549235eca363a31ccb6532ff4bef1cae7b1d4b023f7d3\n",
      "File Hash: 2364207ba60b7f49520e26bf9fe04629c1593e393153607fbdfc85fb404c3128\n",
      "File Hash: 294c0cccd464482ad5c6796c437d20e119fc4d8849eca1285f5d93d22d440d6f\n",
      "File Hash: 297eed22d91620935880847f8cd161f1b50f291a7bb0c8a83fb79d8b7f836c39\n",
      "File Hash: 343502b970df6769f72dc91498aac5ce045f40c8b83d04fa288221a822bd7d3c\n",
      "File Hash: 34b2115c57c5b646be9be8fa1a1fff1033d751b67d5d830394b6488332889118\n",
      "File Hash: 34b5317d04338f5d954a645e678edda2c8e39d5ad008d9e873c57bf9dbe64151\n",
      "File Hash: 35dcc12b3a91e9570eda0f0e2bac26c8d937f324dce00a830e2eedfc2fbefa82\n",
      "File Hash: 3d203cfa9362a3de5653a098f785d0d4c5992bf032cd428d45658b6276e88a1b\n",
      "File Hash: 3f829773b64e8eeefeb7cb3d236fad88540e5ac47ae0f3e22887608fba220e01\n",
      "File Hash: 479d42b197787b191c832cee87b20dc402c6abbc9f14f0146fcdb50d5e1e4c13\n",
      "File Hash: 566cfafc4cbde977f29242e4aedd3557fc67784d12e1b703719ec40d56369d43\n",
      "File Hash: 64fc1708824717655847a396d4b9eb3a0455a247fb13c940404d7a198d000520\n",
      "File Hash: 6d7e260ab64115eeabfa429ff13ad01b385fe094115d05e16b0b4afbe54aba20\n",
      "File Hash: 6e93566f0168ca6398c9b57de39c773c0428c903f047169977f40899514c605d\n",
      "File Hash: 713f1965ed2714b5d9d43c008c8a8d63e6e3cd951340c79dde51714c6128ad4a\n",
      "File Hash: 7df7d947208fb33dc46e8daaea426334af417c4a00b99c3cb20921f656fcf8a3\n",
      "File Hash: 81312ff2153a3f6ca2ebf723f253af2a97bf0682a3ced81d3138ef835cc94e34\n",
      "File Hash: 81eb443598d0d06f7b643653176d07afc4b1dddaa7101948ba9f77a97b460f5b\n",
      "File Hash: 84bacfff2b5a3ba07f036ba45a3a394c4969a7c691e5fbf1a981e3379095be91\n",
      "File Hash: 8667b31ada13bb49fc1eec91dd9777b61675bd87409bfd6c880bb24669af24c7\n",
      "File Hash: 8d452e4e945f3ea8f03d21d9dd654faefcb1ac15400834db15fd7a7f1eabadde\n",
      "File Hash: 8eba86aa9cf040c964b966aab9e7a965d4206046f2817bae2ca2bf74016fa0cf\n",
      "File Hash: 99af77a9d4b6384b2d8df7fbf6381a950026b45d93c97c04543dedcd03ad0b7b\n",
      "Error processing 9ab52ada0a79a93556686842c68d8b9b3af219a2b4ed474f3f20fe9db55a3a40: Failed to read file as PDF. Error: PyCryptodome is required for AES algorithm\n",
      "File Hash: 9d9e8d9c3b68f719be27287f5176fc152a4b79746e1cc4fff582f7c7ac06884c\n",
      "File Hash: 9e0a521d5d960c8157e7546119b226f59122bdf8d4edce9f89199c80cfbd8511\n",
      "File Hash: a6b0fef6485adfc3e47c7bf5eb25e61e9364b1c26431d610a6f16b2dafb4bc98\n",
      "File Hash: ab7bf76d3ea88e9a3813d07ee003ce6c68ecfff7335ae5fc799c1ac13f847299\n",
      "File Hash: b683cbbef4f05292146835325671741853f1bcc32f7b5fc2a32a9a7df221217f\n",
      "File Hash: bf53c3ef22017374f5721e72595a1c83ddb67471dd0b3b9d630dc84ffaef1ae8\n",
      "File Hash: cb10915f45e3c27ccd203dd3f69aad162802d8db568c9010ee696ff631caa41e\n",
      "File Hash: d4b45d1885d49ff8e0b1368747339d473406ca895254cd137d0dcd1ac15ad9aa\n",
      "File Hash: d4b5e6658e994f3a98ed23fc1f907c8d34a38aa0d5edba4170b2ce4cef4dea90\n",
      "File Hash: dd45976381fe4d1b99d07615db4bc32f00f9789e44c63d9ab3cc660e85409806\n",
      "File Hash: e410c77422135319a62b395b50a83609901e0af741e93642aabf5d33211dd38c\n",
      "File Hash: e9d42400e8a9e8876be5e9c3dbd4911e00ee718496d603a0710fc93d4706dac2\n",
      "File Hash: f0135145ea8e9b87173347452e28914990629445469a100599d7ecb77bd9aa92\n",
      "File Hash: f3f61afc58a0fe21bb5c6d864c2e9af23fd990648adefa01cba6a076186fcf23\n",
      "File Hash: f6f5a47c56e6fefb5f3d12e30343b0874436eb9ecfba672d06efa14db9eb5e79\n",
      "Total file hashes where TTPs in text = 0 and TTPs in table or list > 0: 65\n",
      "Total file hashes where TTPs in table or list = 0 and TTPs in text > 0: 44\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"C:\\Users\\Aakanksha Saha\\Documents\\CTI_downloads\\downloads\\20241008_downloads\"\n",
    "password = \"infected\"\n",
    "cti_reports = read_cti_reports(folder_path, file_hashes, password=password)\n",
    "total_reports = len(cti_reports)\n",
    "file_hashes_count_table = 0\n",
    "file_hashes_count_text = 0\n",
    "print(f\"Total number of reports processed: {total_reports}\\n\")\n",
    "\n",
    "for file_hash, result in cti_reports.items():\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error processing {file_hash}: {result['error']}\")\n",
    "    else:\n",
    "        # Get the lengths of TTPs in text and in structured content (tables/lists)\n",
    "        ttps_in_text_length = len(result['ttps_in_text'])\n",
    "        ttps_in_table_or_list_length = len(result['ttps_in_table_or_list'])\n",
    "\n",
    "        if ttps_in_text_length == 0 and ttps_in_table_or_list_length > 0:\n",
    "\n",
    "            file_hashes_count_table += 1\n",
    "        if ttps_in_table_or_list_length == 0 and ttps_in_text_length > 0:\n",
    "            print(f\"File Hash: {file_hash}\")\n",
    "            file_hashes_count_text += 1\n",
    "        \n",
    "        \n",
    "        #print(f\"File Hash: {file_hash}\")\n",
    "        #print(f\"TTPs in text: {ttps_in_text_length} entries\")\n",
    "        #print(f\"TTPs in text: {result['ttps_in_text']}\")\n",
    "        #print(f\"TTPs in table or list: {ttps_in_table_or_list_length} entries\")\n",
    "        #print(f\"TTPs in table or list: {result['ttps_in_table_or_list']}\")\n",
    "        #print(\"-\" * 50)\n",
    "\n",
    "# Output the total count of file hashes that meet the criteria\n",
    "print(f\"Total file hashes where TTPs in text = 0 and TTPs in table or list > 0: {file_hashes_count_table}\")\n",
    "print(f\"Total file hashes where TTPs in table or list = 0 and TTPs in text > 0: {file_hashes_count_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8c3926e-3228-46ef-89dd-888addca2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis hashes: \n",
    "\n",
    "#0c4e350517502f10c3986a7e20d7ce2b78fbc417a36aa22a370a56b124026e9b - https://www.cisa.gov/news-events/cybersecurity-advisories/aa22-055a\n",
    "#2ef3aa28b21deee943bed752a1ac7950382c951a54fd50323bf67b39ee3f5476 - https://www.lacework.com/blog/taking-teamtnt-docker-images-offline/\n",
    "#5d39c90de10384fa86bafb4016761bf84f6d83964a06a38ef4c0db7f0d3b4532 - https://us-cert.cisa.gov/ncas/alerts/aa21-048a\n",
    "#a6c1cbd286cdc07366367c3a9313719dac1c472eb8cd65361f211781eeaf809c - https://us-cert.cisa.gov/ncas/alerts/aa20-301a\n",
    "#e4c8a7ace1cc91c65aadd49419614b71da517763443105b77ee7379d2421528e - https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-320a\n",
    "\n",
    "\n",
    "## Hashes to remove\n",
    "###bff733b5ddd507076bcef720c7d068d3c970c7bb934bde080a29a091432973e8 - https://blog.trendmicro.com/trendlabs-security-intelligence/gamaredon-apt-group-use-covid-19-lure-in-campaigns/\n",
    "##15e4f4ac4a0a5c1b6876c4b4907c66110d319ba03917c991214e8a6edffdb817 - https://blog.trendmicro.com/trendlabs-security-intelligence/gamaredon-apt-group-use-covid-19-lure-in-campaigns/\n",
    "#e9240c31bbb736b7a49df9da3d79f0b65e1173743b2de749da4c55c44fedddf4 - https://unit42.paloaltonetworks.com/molerats-delivers-spark-backdoor/\n",
    "##False list\n",
    "#424f242d75014b9a8f8eda8dbed34a324c32a4106cafe832a5fb5a54f3512230 - https://www.lacework.com/blog/taking-teamtnt-docker-images-offline/\n",
    "##-->This is duplicate of 2ef3\n",
    "##9acadc6a13214395837884616121f6254b86dcab0951564b4d5dbc58c64c5166 - https://www.mandiant.com/resources/blog/sandworm-disrupts-power-ukraine-operational-technology\n",
    "##->This ttp in the text is not really correct because it is a part of the YARA signature content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9b73959-3cfe-4653-9628-4d1c1706cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Hash: 0c4e350517502f10c3986a7e20d7ce2b78fbc417a36aa22a370a56b124026e9b\n",
      "TTPs in text: 15 entries\n",
      "TTPs in table or list: 56 entries\n",
      "Number of common TTPs (Intersection): 12\n",
      "Common TTPs: {'T1041', 'T1071.001', 'T1036.005', 'T1059.006', 'T1027', 'T1204.002', 'T1480', 'T1059.001', 'T1566.001', 'T1132.002', 'T1574.002', 'T1547.001'}\n",
      "TTPs in text but not in table/list (A - B): 3\n",
      "TTPs in text but not in table/list (A - B): {'T1001.001', 'T1572', 'T1005'}\n",
      "TTPs in table/list but not in text (B - A): 44\n",
      "TTPs in table/list but not in text (B - A): {'T1049', 'T1559.002', 'T1560.001', 'T1566.002', 'T1059.007', 'T1102.002', 'T1003.001', 'T1105', 'T1059.005', 'T1548.002', 'T1033', 'T1016', 'T1082', 'T1027.004', 'T1218.005', 'T1113', 'T1053.005', 'T1588.002', 'T1589.002', 'T1087.002', 'T1559.001', 'T1090.002', 'T1047', 'T1518', 'T1219', 'T1132.001', 'T1204.001', 'T1518.001', 'T1218.003', 'T1137.001', 'T1027.003', 'T1083', 'T1218.011', 'T1057', 'T1555', 'T1583.006', 'T1104', 'T1003.004', 'T1555.003', 'T1552.001', 'T1203', 'T1003.005', 'T1562.001', 'T1140'}\n",
      "***After excluding the subtecniques***\n",
      "Number of common TTPs (Intersection): 11\n",
      "Common TTPs: {'T1041', 'T1566', 'T1071', 'T1027', 'T1480', 'T1036', 'T1574', 'T1547', 'T1204', 'T1059', 'T1132'}\n",
      "TTPs in text but not in table/list (A - B): 3\n",
      "TTPs in text but not in table/list (A - B): {'T1001', 'T1572', 'T1005'}\n",
      "TTPs in table/list but not in text (B - A): 30\n",
      "TTPs in table/list but not in text (B - A): {'T1560', 'T1049', 'T1588', 'T1548', 'T1090', 'T1105', 'T1003', 'T1033', 'T1016', 'T1137', 'T1082', 'T1087', 'T1113', 'T1102', 'T1589', 'T1047', 'T1559', 'T1518', 'T1583', 'T1219', 'T1552', 'T1218', 'T1083', 'T1057', 'T1053', 'T1555', 'T1104', 'T1203', 'T1140', 'T1562'}\n",
      "--------------------------------------------------\n",
      "File Hash: 2ef3aa28b21deee943bed752a1ac7950382c951a54fd50323bf67b39ee3f5476\n",
      "TTPs in text: 6 entries\n",
      "TTPs in table or list: 5 entries\n",
      "Number of common TTPs (Intersection): 4\n",
      "Common TTPs: {'T1525', 'T1204.003', 'T1078.004', 'T1610'}\n",
      "TTPs in text but not in table/list (A - B): 2\n",
      "TTPs in text but not in table/list (A - B): {'T1552.001', 'T1613'}\n",
      "TTPs in table/list but not in text (B - A): 1\n",
      "TTPs in table/list but not in text (B - A): {'T1552.002'}\n",
      "***After excluding the subtecniques***\n",
      "Number of common TTPs (Intersection): 5\n",
      "Common TTPs: {'T1078', 'T1552', 'T1525', 'T1204', 'T1610'}\n",
      "TTPs in text but not in table/list (A - B): 1\n",
      "TTPs in text but not in table/list (A - B): {'T1613'}\n",
      "TTPs in table/list but not in text (B - A): 0\n",
      "TTPs in table/list but not in text (B - A): set()\n",
      "--------------------------------------------------\n",
      "File Hash: 5d39c90de10384fa86bafb4016761bf84f6d83964a06a38ef4c0db7f0d3b4532\n",
      "TTPs in text: 22 entries\n",
      "TTPs in table or list: 20 entries\n",
      "Number of common TTPs (Intersection): 19\n",
      "Common TTPs: {'T1566.002', 'T1204.002', 'T1548', 'T1033', 'T1543.004', 'T1053.005', 'T1573.001', 'T1547', 'T1587.001', 'T1041', 'T1027', 'T1583.001', 'T1071.001', 'T1564.001', 'T1583.006', 'T1588.003', 'T1059.004', 'T1053.004', 'T1059'}\n",
      "TTPs in text but not in table/list (A - B): 3\n",
      "TTPs in text but not in table/list (A - B): {'T1059.002', 'T1543.003', 'T1588.004'}\n",
      "TTPs in table/list but not in text (B - A): 1\n",
      "TTPs in table/list but not in text (B - A): {'T1573'}\n",
      "***After excluding the subtecniques***\n",
      "Number of common TTPs (Intersection): 16\n",
      "Common TTPs: {'T1041', 'T1587', 'T1566', 'T1588', 'T1071', 'T1564', 'T1543', 'T1027', 'T1053', 'T1548', 'T1583', 'T1033', 'T1547', 'T1204', 'T1059', 'T1573'}\n",
      "TTPs in text but not in table/list (A - B): 0\n",
      "TTPs in text but not in table/list (A - B): set()\n",
      "TTPs in table/list but not in text (B - A): 0\n",
      "TTPs in table/list but not in text (B - A): set()\n",
      "--------------------------------------------------\n",
      "File Hash: a6c1cbd286cdc07366367c3a9313719dac1c472eb8cd65361f211781eeaf809c\n",
      "TTPs in text: 16 entries\n",
      "TTPs in table or list: 18 entries\n",
      "Number of common TTPs (Intersection): 7\n",
      "Common TTPs: {'T1546.001', 'T1566.002', 'T1562.004', 'T1566.001', 'T1185', 'T1547.001', 'T1056.001'}\n",
      "TTPs in text but not in table/list (A - B): 9\n",
      "TTPs in text but not in table/list (A - B): {'T1560', 'T1074.001', 'T1059.006', 'T1550.002', 'T1114.003', 'T1573.001', 'T1083', 'T1219', 'T1189'}\n",
      "TTPs in table/list but not in text (B - A): 11\n",
      "TTPs in table/list but not in text (B - A): {'T1040', 'T1021.001', 'T1055', 'T1070.004', 'T1059.001', 'T1505.003', 'T1548.002', 'T1003', 'T1547', 'T1082', 'T1218.005'}\n",
      "***After excluding the subtecniques***\n",
      "Number of common TTPs (Intersection): 7\n",
      "Common TTPs: {'T1566', 'T1056', 'T1546', 'T1185', 'T1547', 'T1059', 'T1562'}\n",
      "TTPs in text but not in table/list (A - B): 8\n",
      "TTPs in text but not in table/list (A - B): {'T1560', 'T1550', 'T1074', 'T1083', 'T1114', 'T1219', 'T1189', 'T1573'}\n",
      "TTPs in table/list but not in text (B - A): 9\n",
      "TTPs in table/list but not in text (B - A): {'T1040', 'T1021', 'T1218', 'T1055', 'T1548', 'T1070', 'T1003', 'T1082', 'T1505'}\n",
      "--------------------------------------------------\n",
      "File Hash: e4c8a7ace1cc91c65aadd49419614b71da517763443105b77ee7379d2421528e\n",
      "TTPs in text: 30 entries\n",
      "TTPs in table or list: 36 entries\n",
      "Number of common TTPs (Intersection): 30\n",
      "Common TTPs: {'T1566.004', 'T1078', 'T1567.002', 'T1199', 'T1136', 'T1656', 'T1660', 'T1566', 'T1578.002', 'T1538', 'T1589', 'T1585.001', 'T1114', 'T1219', 'T1074', 'T1552.004', 'T1213.003', 'T1583.001', 'T1018', 'T1083', 'T1530', 'T1484.002', 'T1556.006', 'T1486', 'T1078.002', 'T1552.001', 'T1021.007', 'T1648', 'T1606', 'T1213.002'}\n",
      "TTPs in text but not in table/list (A - B): 0\n",
      "TTPs in text but not in table/list (A - B): set()\n",
      "TTPs in table/list but not in text (B - A): 6\n",
      "TTPs in table/list but not in text (B - A): {'T1217', 'T1598', 'T1539', 'T1621', 'T1657', 'T1204'}\n",
      "***After excluding the subtecniques***\n",
      "Number of common TTPs (Intersection): 26\n",
      "Common TTPs: {'T1078', 'T1199', 'T1213', 'T1136', 'T1656', 'T1660', 'T1566', 'T1538', 'T1589', 'T1114', 'T1583', 'T1578', 'T1219', 'T1074', 'T1552', 'T1021', 'T1567', 'T1018', 'T1083', 'T1530', 'T1484', 'T1486', 'T1585', 'T1556', 'T1648', 'T1606'}\n",
      "TTPs in text but not in table/list (A - B): 0\n",
      "TTPs in text but not in table/list (A - B): set()\n",
      "TTPs in table/list but not in text (B - A): 6\n",
      "TTPs in table/list but not in text (B - A): {'T1217', 'T1598', 'T1539', 'T1621', 'T1657', 'T1204'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "excluded_hashes = {\n",
    "    \"bff733b5ddd507076bcef720c7d068d3c970c7bb934bde080a29a091432973e8\",\n",
    "    \"15e4f4ac4a0a5c1b6876c4b4907c66110d319ba03917c991214e8a6edffdb817\",\n",
    "    \"e9240c31bbb736b7a49df9da3d79f0b65e1173743b2de749da4c55c44fedddf4\",\n",
    "    \"424f242d75014b9a8f8eda8dbed34a324c32a4106cafe832a5fb5a54f3512230\",\n",
    "    \"9acadc6a13214395837884616121f6254b86dcab0951564b4d5dbc58c64c5166\"   \n",
    "}\n",
    "\n",
    "# Creating reports_with_both_ttps without the excluded file hashes\n",
    "reports_with_both_ttps = {\n",
    "    hash_key: result for hash_key, result in cti_reports.items()\n",
    "    if hash_key not in excluded_hashes and \"error\" not in result and result[\"ttps_in_text\"] and result[\"ttps_in_table_or_list\"]\n",
    "}\n",
    "\n",
    "# Printing only those results\n",
    "if reports_with_both_ttps:\n",
    "    #print(f\"Reports with TTPs in both text and table/list: {len(reports_with_both_ttps)}\\n\")\n",
    "\n",
    "    for hash_key, result in reports_with_both_ttps.items():\n",
    "        ttps_in_text_length = len(result['ttps_in_text'])\n",
    "        ttps_in_table_or_list_length = len(result['ttps_in_table_or_list'])\n",
    "        \n",
    "        print(f\"File Hash: {hash_key}\")\n",
    "        print(f\"TTPs in text: {ttps_in_text_length} entries\")\n",
    "        #print(f\"TTPs in text: {result['ttps_in_text']}\")\n",
    "        print(f\"TTPs in table or list: {ttps_in_table_or_list_length} entries\")\n",
    "        #print(f\"TTPs in table or list: {result['ttps_in_table_or_list']}\")\n",
    "\n",
    "        # Extracting just the TTP IDs (without the suffixes)\n",
    "        base_ttp_text = set([ttp[0] for ttp in result['ttps_in_text']])\n",
    "        base_ttp_table = set([ttp[0] for ttp in result['ttps_in_table_or_list']])\n",
    "\n",
    "        # Find common TTPs (Intersection)\n",
    "        common_ttps = base_ttp_text.intersection(base_ttp_table)\n",
    "        \n",
    "        # Find TTPs in text but not in the table (A - B)\n",
    "        ttps_in_text_only = base_ttp_text.difference(base_ttp_table)\n",
    "        \n",
    "        # Find TTPs in table but not in the text (B - A)\n",
    "        ttps_in_table_only = base_ttp_table.difference(base_ttp_text)\n",
    "\n",
    "        print(f\"Number of common TTPs (Intersection): {len(common_ttps)}\")\n",
    "        print(f\"Common TTPs: {common_ttps}\")\n",
    "        # Printing lengths of TTPs that are in text but not in the table/list (A - B) and vice versa (B - A)\n",
    "        print(f\"TTPs in text but not in table/list (A - B): {len(ttps_in_text_only)}\")\n",
    "        print(f\"TTPs in text but not in table/list (A - B): {ttps_in_text_only}\")\n",
    "        print(f\"TTPs in table/list but not in text (B - A): {len(ttps_in_table_only)}\")\n",
    "        print(f\"TTPs in table/list but not in text (B - A): {ttps_in_table_only}\")\n",
    "\n",
    "        print(\"***After excluding the subtecniques***\")\n",
    "\n",
    "        ###Identifying overlap when the sub-technique IDs are not included\n",
    "        # Extracting just the main TTP IDs (ignoring the sub-technique part if present)\n",
    "        base_ttp_text_1 = set([ttp[0].split('.')[0] for ttp in result['ttps_in_text']])\n",
    "        base_ttp_table_1 = set([ttp[0].split('.')[0] for ttp in result['ttps_in_table_or_list']])\n",
    "\n",
    "        # Find common TTPs (Intersection)\n",
    "        common_ttps_1 = base_ttp_text_1.intersection(base_ttp_table_1)\n",
    "        \n",
    "        # Find TTPs in text but not in the table (A - B)\n",
    "        ttps_in_text_only_1 = base_ttp_text_1.difference(base_ttp_table_1)\n",
    "        \n",
    "        # Find TTPs in table but not in the text (B - A)\n",
    "        ttps_in_table_only_1 = base_ttp_table_1.difference(base_ttp_text_1)\n",
    "\n",
    "        print(f\"Number of common TTPs (Intersection): {len(common_ttps_1)}\")\n",
    "        print(f\"Common TTPs: {common_ttps_1}\")\n",
    "        # Printing lengths of TTPs that are in text but not in the table/list (A - B) and vice versa (B - A)\n",
    "        print(f\"TTPs in text but not in table/list (A - B): {len(ttps_in_text_only_1)}\")\n",
    "        print(f\"TTPs in text but not in table/list (A - B): {ttps_in_text_only_1}\")\n",
    "        print(f\"TTPs in table/list but not in text (B - A): {len(ttps_in_table_only_1)}\")\n",
    "        print(f\"TTPs in table/list but not in text (B - A): {ttps_in_table_only_1}\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "       \n",
    "else:\n",
    "    print(\"No reports found with both TTPs in text and table/list.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6036614b-e1a9-45f0-af67-f1f7c499a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def identify_structured_sections(content):\n",
    "    \"\"\"\n",
    "    Identifies potential structured sections (like lists or tables) in the PDF text content by\n",
    "    detecting patterns such as bullet points, numbered lists, or tabular-like text structures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content : str\n",
    "        The text content of the PDF to analyze.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with plain text and structured sections.\n",
    "    \"\"\"\n",
    "    # Split the content into lines for easier processing\n",
    "    lines = content.splitlines()\n",
    "\n",
    "    structured_content = []\n",
    "    plain_text_content = []\n",
    "    \n",
    "    in_structured_section = False\n",
    "    structured_section = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        \n",
    "        # Detect simple bullet points, numbered lists, or table-like sections\n",
    "        if re.match(r'^(?:\\d+\\.\\d+|\\d+\\.)', stripped_line):  # This matches numeric lists (1., 1.1, etc.)\n",
    "            in_structured_section = True\n",
    "            structured_section.append(stripped_line)\n",
    "        elif re.match(r'^\\s{2,}', stripped_line):  # Indentation in the content indicates tabular format\n",
    "            in_structured_section = True\n",
    "            structured_section.append(stripped_line)\n",
    "        else:\n",
    "            if in_structured_section:\n",
    "                # We assume the structured section ends here\n",
    "                structured_content.append(' '.join(structured_section))\n",
    "                structured_section = []\n",
    "                in_structured_section = False\n",
    "            plain_text_content.append(stripped_line)\n",
    "\n",
    "    # In case there's an unclosed structured section\n",
    "    if structured_section:\n",
    "        structured_content.append(' '.join(structured_section))\n",
    "\n",
    "    # Join plain text content together into a single block\n",
    "    plain_text = ' '.join(plain_text_content)\n",
    "\n",
    "    return {\n",
    "        \"structured_content\": ' '.join(structured_content),\n",
    "        \"plain_text_content\": plain_text\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_pdf_cti_report(pdf_content):\n",
    "    \"\"\"\n",
    "    Separates plain text content from structured (list/table-like) content in a PDF, \n",
    "    then extracts TTPs from each section.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf_content : str\n",
    "        The complete content of a CTI report extracted from a PDF.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with TTPs found in text, list, and table-like content.\n",
    "    \"\"\"\n",
    "    ttp_pattern = r'\\b(T[0-9]{4}(?:\\.[0-9]{3})?)\\b'\n",
    "\n",
    "    # Identify structured sections like lists or table-like data\n",
    "    sections = identify_structured_sections(pdf_content)\n",
    "    \n",
    "    # Extract TTPs from structured content (detected as lists or table-like)\n",
    "    ttps_in_structured_content = extract_ttps(sections['structured_content'], ttp_pattern)\n",
    "    ttps_in_structured_content = list(set(ttps_in_structured_content))\n",
    "\n",
    "    # Extract TTPs from plain text content (excluding structured sections)\n",
    "    ttps_in_text = extract_ttps(sections['plain_text_content'], ttp_pattern)\n",
    "    ttps_in_text = list(set(ttps_in_text))\n",
    "\n",
    "    # Ensure that TTPs in text and structured data are truly separate\n",
    "    #if set(ttps_in_text).issubset(ttps_in_structured_content):\n",
    "    #    ttps_in_text = []\n",
    "\n",
    "    return {\n",
    "        \"ttps_in_text\": ttps_in_text,\n",
    "        \"ttps_in_table_or_list\": ttps_in_structured_content\n",
    "    }\n",
    "\n",
    "def extract_ttps(content, pattern):\n",
    "    \"\"\"\n",
    "    Extracts TTPs from the given content using the specified regex pattern.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content : str\n",
    "        The text content to search for TTPs.\n",
    "    pattern : str\n",
    "        The regex pattern to match TTPs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of matched TTPs.\n",
    "    \"\"\"\n",
    "    return re.findall(pattern, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2128fb95-2285-41a7-8b71-c9d92655ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_ttps(content, pattern):\n",
    "    \"\"\"\n",
    "    Extracts TTPs from the given content using the specified regex pattern.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content : str\n",
    "        The text content to search for TTPs.\n",
    "    pattern : str\n",
    "        The regex pattern to match TTPs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of matched TTPs.\n",
    "    \"\"\"\n",
    "    return re.findall(pattern, content)\n",
    "\n",
    "def parse_cti_report(content):\n",
    "    \"\"\"\n",
    "    Separates plain text content from table or list content, then extracts TTPs from each section.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content : str\n",
    "        The complete content of a CTI report.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with TTPs found in text, list, and table content.\n",
    "    \"\"\"\n",
    "    ttp_pattern = r'\\b(T[0-9]{4}([.][0-9]{3})?)\\b'\n",
    "    \n",
    "    # Convert the content to a BeautifulSoup object for easier parsing\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "    # 1. Extract all structured content: tables and lists with TTPs\n",
    "    ttps_in_table_or_list = []\n",
    "\n",
    "    # Extract from tables\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            for cell in row.find_all(\"td\"):\n",
    "                ttps_in_table_or_list.extend(extract_ttps(cell.get_text(), ttp_pattern))\n",
    "    \n",
    "    # Extract from unordered lists\n",
    "    for ul in soup.find_all(\"ul\"):\n",
    "        for li in ul.find_all(\"li\"):\n",
    "            ttps_in_table_or_list.extend(extract_ttps(li.get_text(), ttp_pattern))\n",
    "\n",
    "    # Extract from ordered lists\n",
    "    for ol in soup.find_all(\"ol\"):\n",
    "        for li in ol.find_all(\"li\"):\n",
    "            ttps_in_table_or_list.extend(extract_ttps(li.get_text(), ttp_pattern))\n",
    "\n",
    "    # Remove duplicates from structured content\n",
    "    ttps_in_table_or_list = list(set(ttps_in_table_or_list))\n",
    "\n",
    "    # 2. Extract plain text content, excluding tables and lists\n",
    "    for element in soup([\"table\", \"ul\", \"ol\"]):\n",
    "        element.extract()  # Remove structured elements from soup to isolate plain text\n",
    "\n",
    "    # Find TTPs in plain text content\n",
    "    plain_text_content = soup.get_text()\n",
    "    ttps_in_text = extract_ttps(plain_text_content, ttp_pattern)\n",
    "    ttps_in_text = list(set(ttps_in_text))\n",
    "\n",
    "    # 3. Check if TTPs in text and structured data are truly separate\n",
    "    #if set(ttps_in_text).issubset(ttps_in_table_or_list):\n",
    "    #    ttps_in_text = []\n",
    "\n",
    "    return {\n",
    "        \"ttps_in_text\": ttps_in_text,\n",
    "        \"ttps_in_table_or_list\": ttps_in_table_or_list\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
