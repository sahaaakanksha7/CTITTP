{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c95041-be04-4bdd-83e6-c279eac36ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def extract_fqdn_and_date(file_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the FQDN from the 'url' field and the 'date' from the provided JSON lines.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file containing JSON entries.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the FQDN and date for each entry.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line of the JSONL file\n",
    "        for line in file:\n",
    "            entry = json.loads(line)\n",
    "            # Extract the FQDN from the 'url'\n",
    "            url = entry.get(\"url\", \"\")\n",
    "            parsed_url = urlparse(url)\n",
    "            fqdn = parsed_url.netloc  # Get the FQDN part from the URL\n",
    "\n",
    "            # Extract the 'date'\n",
    "            date = entry.get(\"date\", \"\")\n",
    "\n",
    "            # Append the FQDN and date to the results\n",
    "            results.append((fqdn, date))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb35681-84ef-4507-8ece-91ce1734f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "file_path = r\"C:\\Users\\Aakanksha Saha\\Documents\\CTI_downloads\\malpedia_20220718\\malpedia_20220718\\malpedia-db_2022-07-18_downloader.jsonl\"  # Replace with the actual file path\n",
    "malpedia_fqdn_and_dates = extract_fqdn_and_date(file_path)\n",
    "print(len(set(fqdn for fqdn, date in malpedia_fqdn_and_dates)))\n",
    "# Display the results\n",
    "#for fqdn, date in fqdn_and_dates:\n",
    "#    print(f\"FQDN: {fqdn}, Date: {date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6093994e-322e-4c64-b435-ed01b27d49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def extract_successful_urls(file_path: str):\n",
    "    \"\"\"\n",
    "    Extracts the FQDN from the 'url' field only for entries where the 'download_status' is 200 (successful).\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file containing JSON entries.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of FQDNs for entries with a successful download status.\n",
    "    \"\"\"\n",
    "    successful_urls = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line of the JSONL file\n",
    "        for line in file:\n",
    "            entry = json.loads(line)\n",
    "\n",
    "            # Check if 'download_status' is 200\n",
    "            if entry.get('download_status') == 200:\n",
    "                # Extract the FQDN from the 'url'\n",
    "                url = entry.get(\"url\", \"\")\n",
    "                parsed_url = urlparse(url)\n",
    "                fqdn = parsed_url.netloc  # Get the FQDN part from the URL\n",
    "\n",
    "                # Append the FQDN to the list\n",
    "                if fqdn:\n",
    "                    successful_urls.append(fqdn)\n",
    "\n",
    "    return successful_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110ea9ab-3190-43a5-b592-cbca04f1629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "file_path = r\"C:\\Users\\Aakanksha Saha\\Documents\\CTI_downloads\\downloads\\20241008_downloads.jsonl\"  # Replace with the actual file path\n",
    "mitre_successful_fqdns = extract_successful_urls(file_path)\n",
    "print(len(set(mitre_successful_fqdns)))\n",
    "# Display the results\n",
    "#for fqdn in successful_fqdns:\n",
    "#    print(f\"FQDN: {fqdn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00cdb7de-6868-4c59-bb6e-4ed4fbc03a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fqdns(malpedia_fqdn_and_dates: list, mitre_successful_fqdns: list):\n",
    "    \"\"\"\n",
    "    Compares two sets of FQDNs, returning the overlap, A-B, B-A, and their counts.\n",
    "\n",
    "    Args:\n",
    "        fqdn_and_dates (list): A list of tuples containing FQDN and date.\n",
    "        successful_fqdns (list): A list of FQDNs with successful download statuses.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the overlap, A-B, B-A, and counts for each.\n",
    "    \"\"\"\n",
    "    # Extract unique FQDNs from both lists\n",
    "    unique_fqdn_dates = set(fqdn for fqdn, date in malpedia_fqdn_and_dates)  # Unique FQDNs from fqdn_and_dates\n",
    "    unique_successful_fqdns = set(mitre_successful_fqdns)  # Unique FQDNs from successful_fqdns\n",
    "\n",
    "    # Find the overlap\n",
    "    overlap = unique_fqdn_dates.intersection(unique_successful_fqdns)\n",
    "\n",
    "    # Find A - B (FQDNs in fqdn_and_dates but not in successful_fqdns)\n",
    "    a_minus_b = unique_fqdn_dates.difference(unique_successful_fqdns)\n",
    "\n",
    "    # Find B - A (FQDNs in successful_fqdns but not in fqdn_and_dates)\n",
    "    b_minus_a = unique_successful_fqdns.difference(unique_fqdn_dates)\n",
    "\n",
    "    # Return the results along with the counts\n",
    "    return {\n",
    "        'overlap': overlap,\n",
    "        'A-B': a_minus_b,\n",
    "        'B-A': b_minus_a,\n",
    "        'overlap_count': len(overlap),\n",
    "        'A-B_count': len(a_minus_b),\n",
    "        'B-A_count': len(b_minus_a),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9b790e-7adb-47b5-9bd6-d9d156dfcdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap (A ∩ B): {'www.slideshare.net', 'researchcenter.paloaltonetworks.com', 'threatpost.com', 'www.crowdstrike.com', 'lab52.io', 'www.ic3.gov', 'security.web.cern.ch', 'cybleinc.com', 'blogs.cisco.com', 'blog.netlab.360.com', 'redcanary.com', 'dragos.com', 'www.brighttalk.com', 'blog.360totalsecurity.com', 'msrc.microsoft.com', 'www.cisa.gov', 'blogs.blackberry.com', 'www.justice.gov', 'media.kasperskycontenthub.com', 'www.blackberry.com', 'blog.aquasec.com', 'labs.sentinelone.com', 'blog.certfa.com', 'www.trustwave.com', 'www.darkreading.com', 'blog.google', 'attack.mitre.org', 'pylos.co', 'www.esentire.com', 'vb2020.vblocalhost.com', 'www.avira.com', 'cloudblogs.microsoft.com', 'reaqta.com', 'www.whitehouse.gov', 'query.prod.cms.rt.microsoft.com', 'www.paloaltonetworks.com', 'www.rewterz.com', 'www.domaintools.com', 'www.europol.europa.eu', 'arstechnica.com', 'community.broadcom.com', 'therecord.media', 'blogs.technet.microsoft.com', 'assets.sentinelone.com', 'documents.trendmicro.com', 'download.bitdefender.com', 'www.microsoft.com', 'www.anomali.com', 'cdn0.vox-cdn.com', 'www.cylance.com', 'www.fireeye.com', 'www.flashpoint-intel.com', 'docs.broadcom.com', 'www.rapid7.com', 'www.cybercom.mil', 'www.fox-it.com', 'www.sentinelone.com', 'www.recordedfuture.com', 'msrc-blog.microsoft.com', 'blog.bushidotoken.net', 'www.ironnet.com', 'threatconnect.com', 'www.forbes.com', 'www.mcafee.com', 'media.defense.gov', 'www.mandiant.com', 'blog-assets.f-secure.com', 'netzpolitik.org', 'securelist.com', 'www.dragos.com', 'research.checkpoint.com', 'www.eweek.com', 'thedfirreport.com', 'www.deepinstinct.com', 'web.archive.org', 'logrhythm.com', 'cycraft.com', 'www.secureworks.com', 'f.hubspotusercontent30.net', 'businessinsights.bitdefender.com', 'www.trendmicro.com', 'info.lookout.com', 'www.volexity.com', 'blog.alyac.co.kr', 'www.zscaler.com', 'www.zdnet.com', 'download.microsoft.com', 'blogs.microsoft.com', 'www.ptsecurity.com', 'www.rsa.com', 'cdn-cybersecurity.att.com', 'www.lacework.com', 'securingtomorrow.mcafee.com', 'www.welivesecurity.com', 'adversary.crowdstrike.com', 'www.cyberscoop.com', 'www.virusbulletin.com', 'usa.visa.com', 'twitter.com', 'www.proofpoint.com', 'www.leonardo.com', 'www.f-secure.com', 'www.symantec.com', 'docs.microsoft.com', 'threatvector.cylance.com', 'www.youtube.com', 'us-cert.cisa.gov', 'blogs.jpcert.or.jp', 'go.group-ib.com', 'www.pwc.co.uk', 'blog.malwarebytes.com', 'blog.morphisec.com', 'www.trendmicro.de', 'home.treasury.gov', 'research.nccgroup.com', 'news.sophos.com', 'go.crowdstrike.com', 'www.bleepingcomputer.com', 'www.cadosecurity.com', 'blog.talosintelligence.com', 'objective-see.com', 'noticeofpleadings.com', 'www.bitdefender.com', 'www.ncsc.gov.uk', 'blog.trendmicro.com', 'blog.checkpoint.com', 'www.forcepoint.com', 'foxitsecurity.files.wordpress.com', 'www.intezer.com', 'ti.dbappsecurity.com.cn', 'www.gov.uk', 'arcticwolf.com', 'iranthreats.github.io', 'vblocalhost.com', 'www.cybereason.com', 'www.us-cert.gov', 'www.wired.com', 'insight-jp.nttsecurity.com', 'citizenlab.ca', 'www.uptycs.com', 'unit42.paloaltonetworks.com', 'thehackernews.com', 'www.talent-jump.com', 'www.accenture.com', 'www.infosecurity-magazine.com', 'www.threatconnect.com', 'github.com', 'go.recordedfuture.com', 'www.clearskysec.com', 'cdn2.hubspot.net', 'blog.sygnia.co', 'securityintelligence.com', 'info.phishlabs.com', 'www.bbc.com', 'www.cert.ssi.gouv.fr', 'securityaffairs.co', 'symantec-enterprise-blogs.security.com', 'blog.qualys.com'}, Count: 158\n",
      "A - B (In malpedia but not in MITRE) Count: 1508\n",
      "B - A (In MITRE but not in Malpedia): {'fortune.com', 'learn.microsoft.com', 'airbus-cyber-security.com', 'www.threatminer.org', 'blog.scilabs.mx', 'www.csmonitor.com', 'blogs.forcepoint.com', 'citizenlab.org', 'www.threatstream.com', 'telefonicatech.com', 'www.issuemakerslab.com', 'cyberscoop.com', 'carnal0wnage.attackresearch.com', 'www.iranwatch.org', 'tools.kali.org', '401trg.github.io', 'crowdstrike.lookbookhq.com', 'usa.kaspersky.com', 'www.amnestyusa.org', 'www.malwarebytes.com', 'recon.cx'}, Count: 21\n"
     ]
    }
   ],
   "source": [
    "# Compare the FQDNs\n",
    "comparison_results = compare_fqdns(malpedia_fqdn_and_dates, mitre_successful_fqdns)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Overlap (A ∩ B): {comparison_results['overlap']}, Count: {comparison_results['overlap_count']}\")\n",
    "#print(f\"Overlap (A ∩ B) Count: {comparison_results['overlap_count']}\")\n",
    "#print(f\"A - B (In malpedia but not in MITRE): {comparison_results['A-B']}, Count: {comparison_results['A-B_count']}\")\n",
    "print(f\"A - B (In malpedia but not in MITRE) Count: {comparison_results['A-B_count']}\")\n",
    "print(f\"B - A (In MITRE but not in Malpedia): {comparison_results['B-A']}, Count: {comparison_results['B-A_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7724bff-7cbf-4efa-a5c1-2074c492ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection of second-level domains: {'crowdstrike', 'redcanary', 'youtube', 'hubspotusercontent30', 'intezer', 'forbes', 'talent-jump', 'virusbulletin', 'proofpoint', 'sentinelone', 'brighttalk', 'securityintelligence', '360', 'sygnia', 'phishlabs', 'certfa', 'accenture', 'cern', 'kaspersky', 'cycraft', 'group-ib', 'bleepingcomputer', 'reaqta', 'symantec', 'arstechnica', 'logrhythm', 'aquasec', 'treasury', 'vblocalhost', 'whitehouse', 'securelist', 'deepinstinct', 'fireeye', 'eweek', 'hubspot', 'trendmicro', 'europa', 'nttsecurity', 'alyac', 'ironnet', 'lab52', 'cisco', 'thedfirreport', 'broadcom', 'justice', 'uptycs', 'wordpress', 'cybleinc', 'bitdefender', 'welivesecurity', 'paloaltonetworks', 'netzpolitik', 'nccgroup', 'att', 'us-cert', 'esentire', 'recordedfuture', 'cybercom', 'f-secure', 'trustwave', 'ptsecurity', 'leonardo', 'kasperskycontenthub', 'darkreading', '360totalsecurity', 'checkpoint', 'morphisec', 'defense', 'infosecurity-magazine', 'github', 'forcepoint', 'lookout', 'flashpoint-intel', 'dragos', 'www', 'thehackernews', 'zscaler', 'archive', 'rsa', 'cylance', 'pylos', 'security', 'rapid7', 'threatpost', 'bushidotoken', 'cisa', 'qualys', 'mcafee', 'noticeofpleadings', 'bbc', 'blackberry', 'objective-see', 'jpcert', 'volexity', 'therecord', 'zdnet', 'cybereason', 'dbappsecurity', 'secureworks', 'citizenlab', 'mandiant', 'ic3', 'blog', 'ssi', 'mitre', 'anomali', 'talosintelligence', 'arcticwolf', 'twitter', 'pwc', 'microsoft', 'rewterz', 'domaintools', 'cadosecurity', 'clearskysec', 'avira', 'lacework', 'cyberscoop', 'fox-it', 'wired', 'threatconnect', 'malwarebytes', 'ncsc', 'slideshare', 'securityaffairs', 'sophos', 'visa', 'vox-cdn'}\n",
      "Domains in MITRE but not in Malpedia: {'threatstream', 'iranwatch', 'kali', 'telefonicatech', 'scilabs', 'airbus-cyber-security', 'csmonitor', 'attackresearch', 'amnestyusa', 'lookbookhq', 'recon', 'issuemakerslab', 'fortune', 'threatminer'}\n"
     ]
    }
   ],
   "source": [
    "import tldextract\n",
    "\n",
    "def extract_second_level_domain(fqdn):\n",
    "    \"\"\"\n",
    "    Extracts the second-level domain (SLD) from a given FQDN.\n",
    "    \n",
    "    Args:\n",
    "        fqdn (str): Fully Qualified Domain Name (FQDN).\n",
    "        \n",
    "    Returns:\n",
    "        str: The second-level domain of the FQDN.\n",
    "    \"\"\"\n",
    "    extracted = tldextract.extract(fqdn)\n",
    "    return extracted.domain  # This gives you the second-level domain (SLD)\n",
    "\n",
    "\n",
    "# Extract unique second-level domains from both lists\n",
    "unique_second_level_malpedia = set(extract_second_level_domain(fqdn) for fqdn, date in malpedia_fqdn_and_dates)\n",
    "unique_second_level_mitre = set(extract_second_level_domain(fqdn) for fqdn in mitre_successful_fqdns)\n",
    "\n",
    "# Find the intersection of second-level domains\n",
    "overlap = unique_second_level_malpedia.intersection(unique_second_level_mitre)\n",
    "b_minus_a = unique_second_level_mitre.difference(unique_second_level_malpedia)\n",
    "# Print the result\n",
    "print(f\"Intersection of second-level domains: {overlap}\")\n",
    "print(f\"Domains in MITRE but not in Malpedia: {b_minus_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c8e33-e524-4554-9be1-c316c780e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
